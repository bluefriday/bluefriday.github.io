{"meta":{"title":"오늘처럼","subtitle":"test","description":"test","author":"Heechang Lee","url":"http://bluefriday.github.io","root":"/"},"pages":[],"posts":[{"title":"docker registry file structure","slug":"docker-registry-file-structure","date":"2020-11-19T01:01:37.000Z","updated":"2020-11-19T10:08:41.744Z","comments":true,"path":"2020/11/19/docker-registry-file-structure/","link":"","permalink":"http://bluefriday.github.io/2020/11/19/docker-registry-file-structure/","excerpt":"","text":"Docker registry 내부 구조이번에는 private registry에 도커 이미지를 저장하였을 때 이미지가 저장되는 구조에 대해서 살펴본다. 먼저 간단한 registry를 구동하는데, registry 내부의 디렉토리 구조를 살펴보기 위하여 docker volume(-v) 옵션을 이용하여 registry 내부의 데이터 디렉터리 경로를 호스트 환경으로 노출시켜서 구동하도록 하자. 1$ docker run -d --name&#x3D;registry -p 5000:5000 -v $PWD&#x2F;registry:&#x2F;var&#x2F;lib&#x2F;registry registry:latest docker registry의 기본적인 데이터 디렉토리 위치는 /var/lib/registry 이며 해당 경로는 registry config 파일을 수정하여 변경 가능하다. 최초 registry를 구동한 시점에서는 해당 경로에 기본적으로 생성되는 파일이나 디렉토리는 없지만, 이미지가 push 된 시점부터 해당 경로에 이미지와 관련된 파일이 생성된다. 아무런 파일도 없으면 디렉토리 구조를 살펴볼 수 없으므로, 여기서는 테스트를 위해 로컬 환경에 registry를 구동하고 태그를 변경하여 임의의 localhost:5000/HARANG:latest 이라는 이름의 이미지를 registry에 push 하였다. push 후에 tree 명령어를 이용하여 디렉토리 구조를 출력한 결과는 아래와 같다. 12345678910111213141516171819202122232425262728293031323334353637383940414243registry&#x2F;└── docker └── registry └── v2 ├── blobs │ └── sha256 │ ├── 1c │ │ └── 1c889e8ec921d2ebb0c6730d06943b96269194f3f50d1ada90c903a99e58d8d1 │ │ └── data │ ├── 20 │ │ └── 2071770b9246dde806828d558bcaea76ce3d07654691ffe1a71d64175113e185 │ │ └── data │ ├── ae │ │ └── aed400a7ca9e93f9219bec5740ca3b5b70d4dda6b38023c1021dd6a2500997ca │ │ └── data │ └── b5 │ └── b5464cb6b67eb599fa7da169d3f31d239540205aeba7689df57a419f16da48da │ └── data └── repositories └── HARANG ├── _layers │ └── sha256 │ ├── 1c889e8ec921d2ebb0c6730d06943b96269194f3f50d1ada90c903a99e58d8d1 │ │ └── link │ ├── 2071770b9246dde806828d558bcaea76ce3d07654691ffe1a71d64175113e185 │ │ └── link │ └── b5464cb6b67eb599fa7da169d3f31d239540205aeba7689df57a419f16da48da │ └── link ├── _manifests │ ├── revisions │ │ └── sha256 │ │ └── aed400a7ca9e93f9219bec5740ca3b5b70d4dda6b38023c1021dd6a2500997ca │ │ └── link │ └── tags │ └── latest │ ├── current │ │ └── link │ └── index │ └── sha256 │ └── aed400a7ca9e93f9219bec5740ca3b5b70d4dda6b38023c1021dd6a2500997ca │ └── link └── _uploads 위 tree구조를 분석해보자. 먼저 기준 디렉토리인 registry 밑으로 /docker/registry/v2 까지의 디렉토리명은 docker registry v2 에서 이미 지정되어 있다. 그 하위 디렉토리는 blob 과 registry로 나누어진다. blob 은 Binary Large Object의 약자로 대용량 바이너리(이진) 객체를 저장하기 위한 파일 형식이다. 주로 기존의 데이터베이스에 저장하기 어려운 이미지, 동영상 등의 바이너리 데이터를 담는 개체이며 여기서는 실제 docker image 를 물리적으로 나누어 blob 파일로 저장하고 있다. 따라서 현재 push한 이미지 HARANG은 4개의 blob 파일로 나누어져서 registry에 저장됨을 확인할 수 있다. 각각의 blob 파일들은 서로 겹치지 않는 해쉬값으로 분류되어 해쉬값과 동일한 디렉토리 이름으로 저장된다. 즉 1개의 이미지는 N개의 blob 파일로 나누어져 저장되며 추가적으로 이 blob 파일들 중에는 1)해당 이미지의 Dockerfile 정보를 포함하고 있는 blob파일과, 2)이미지의 레이어 구성정보를 포함하고 있는 blob파일(이하 meta blob)도 포함되어 있다. 위 예제의 경우 동일한 색깔로 해당 blob파일을 표시하였다. blob 이 실제 물리적인 데이터를 저장하는 공간이라면, repositories 디렉토리는 주로 이미지의 구성 정보, 이력, 태그 등에 대한 메타 정보를 나누어 저장하고 있다. registry는 먼저 1단계 구분으로 image의 이름을 기준으로 분류한다. 현재는 1개의 이미지만 push 하였기 때문에 위의 tree 구조에서는 repositories 항목 하위에 바로 HARANG 이라는 디렉토리가 하나만 존재 하고 있다. 좀 더 하위의 디렉토리를 확인해보면 ‘_layer’, ‘_manifests’, ‘_uploads’의 3개의 디렉토리로 나누어진다. ‘_layer’ 디렉토리는 meta blob(이미지 구성정보를 포함하고 있는 blob)을 제외한 다른 모든 blob파일의 경로를 보유하고 있다. 위 예제에서도 blob 하위의 4개 layer 중 이미지 구성정보를 담고 있는 ae(로 시작하는) layer 를 제외한 다른 3개의 blob 파일에 대한 정보를 표시하고 있는 것을 확인할 수 있다. ‘_manifest’ 디렉토리는 이미지의 메타 정보를 관리하고 있다. ‘_layer’ 가 실제 이미지의 물리적 경로를 보유하고 있다면, ‘_manifest’는 특정 이미지가 현재 어떤 태그를 가지고 있으며, 어떤 이미지 레이어들로 구성되어 있는지에 대한 메타 정보를 가지고 있다. 하위의 revision 디렉토리에서는 메타 정보를 담고 있는 ae layer를 가지고 있는 것을 확인할 수 있다. 또한 태그에 대한 정보도 가지고 있는데, 위의 경우 HARANG이라는 이미지의 latest 태그 정보를 표시하고 있다. 하위의 index 디렉토리에는 (이미지가 같은 태그로 overwrite 되었을 경우) 해당 태그로 들어온 모든 meta blob 주소를 가지고 있으며, current 디렉토리에서는 그 index 중에서 가장 마지막에 overwrite 된 meta blob 의 주소를 가지고 있다. ‘_upload’ 디렉토리는 업로드가 진행되고 있는 이미지의 임시 파일을 저장한다. 정상적으로 이미지가 push 되는 경우에는 비어있지만, push 가 진행되는 동안 temp 파일들이 쌓이는것을 확인할 수 있다. 또한 registry api를 이용하여 layer 단위로 이미지를 push 하는 경우에도 하나의 manifest로 묶이기 전의 layer 파일들은 이 디렉토리 하위에서 확인할 수 있다. registry api 를 이용한 push는 다른 주제로 별도로 정리되어 있다.","categories":[],"tags":[]},{"title":"docker registry service","slug":"docker-registry-service","date":"2020-11-19T00:54:41.000Z","updated":"2020-11-19T10:00:19.289Z","comments":true,"path":"2020/11/19/docker-registry-service/","link":"","permalink":"http://bluefriday.github.io/2020/11/19/docker-registry-service/","excerpt":"","text":"Docker registry컨테이너를 이용하여 어플리케이션의 실행환경을 가상화하기 위해서 도커 이미지가 필요한 만큼 이미지의 관리 또한 중요하다. 특히 개발/운영 환경에서 CI/CD 를 적용하여 이미지를 배포 하는 경우에는 이미지를 로컬 환경에 보관하는 것보다 저장가능한 다른 저장소에 보관하는 것이 좋다. 도커 측은 사용자가 컨테이너 생성을 위한 이미지를 저장하고 다른 사용자들과 공유할 수 있도록 컨테이너 이미지에 대한 저장소(이하 registry) 서비스를 제공하고 있다. 이를 통하여 사용자는 쉽게 이미지를 registry에 저장(push)하고 필요한 이미지를 받아올(pull) 수 있다. 이러한 registry 서비스는 공개유형에 따라 public, private 으로 구분 가능하다. public registry의 경우 모든 사람들이 자유롭게 이용할 수 있도록 이미지가 공개되어 있으며, 사용자들은 필요에 따라 자신이 원하는 이미지를 검색하고 해당 이미지를 사용할 수 있다. private registry는 사용자가 자신만의 별도의 registry를 따로 생성하여 custom image들을 보관할 수 있도록 해준다. 여기서는 public/private registry에 대하여 조금 더 다뤄본다. Docker public registry도커 측은 docker hub(https://hub.docker.com/) 라는 public registry를 제공한다. 물론 docker hub 의 경우 회원가입/로그인 후에 private한 용도로도 사용할 수 있으나 docker hub 자체는 public registry로서의 성격이 더 크고, 후술할 docker registry 가 private registry 로서의 기능을 제공하고 있으므로 여기서는 public registry 로서의 docker hub 만을 알아보기로 한다.docker hub를 통하여 사용자는 이미지를 조회/검색할 수 있으며, 특정 이미지에 대한 description을 확인할 수 있다. 또한 CLI 환경에서도 docker search 명령어를 이용할 경우 docker hub에서 사용되는 이미지를 조회할 수 있다. 아래 화면은 각각 docker hub와 docker client를 이용하여 nginx 이미지를 조회한 예이다. [그림1 : docker hub / docker search 등을이용하여 nginx 이미지를 조회한 예] 이렇게 조회한 이미지의 경우 CLI 환경에서 docker pull 명령어로 누구나 해당 이미지를 조회할 수 있다. Docker private registry위와 같이 public registry 인 docker hub를 이용하여 자주 사용되는 이미지들을 쉽게 받아서 실행 시킬 수 있지만, 컨테이너를 이용하여 이미지를 받고 또 받은 이미지를 이용하여 새로운 이미지를 생성하다보면 타인에게 공개되지 않고 자신만이 사용할 수 있는 이미지들도 존재하게 된다. 이러한 이미지는 public registry에 올리기 어려운데 이럴 때 사용자가 자신의 이미지를 저장하고 특정 개인/집단에게만 공유할 수 있도록 해주는 private registry를 사용할 수 있다. private registry는 host PC에 background daemon으로 구동되는 것이 아니라, host PC에 docker 플랫폼 위에 도커 컨테이너로서 구동된다. 즉, 컨테이너 이미지를 저장하는 저장소 또한 컨테이너로 구동되어지는 방식이다. 당연히 host PC에는 Docker 가 필수적으로 설치되어 있어야 하며, registry 컨테이너를 구동하기 위한 docker image가 필요하다. 해당 이미지는 docker hub에서 쉽게 조회해서 받아올 수 있다. 아래와 같은 명령어를 사용하여 registry 이미지를 조회하고 docker hub를 통해서 내려받자. 123$ docker search registryNAME DESCRIPTION STARS OFFICIAL AUTOMATEDregistry The Docker Registry 2.0 implementation for s… 2053 [OK] 받아온 이미지로 docker registry container를 구동하기 전에 알아둬야 할 사항들이 있다. 먼저 registry는 내부적으로 5000번 포트를 사용한다. 컨테이너로 registry 를 구동한 후에 외부에서 해당 컨테이너에 접속하기 위해서 5000번 포트를 노출시켜줄 필요가 있다.또한 저장소 성격을 가진 컨테이너이므로 해당 컨테이너가 삭제 될 경우 저장되어 있는 내용(여기서는 도커 이미지)이 모두 지워지는 것을 방지하기 위하여 미리 컨테이너 내부의 실제 저장 파일 위치를 docker volume 으로 연결해줘야 한다. 1$ docker run -d --name&#x3D;private_registry -p 5000:5000 -v &#x2F;test&#x2F;registry_data:&#x2F;var&#x2F;lib&#x2F;registry registry:latest 이제 컨테이너로 private registry를 구동하였다. 이 registry는 로컬 port 5000번으로 노출되어 있어, 해당 포트를 통해 registry pull/push를 사용할 수 있다. 먼저 호스트에 있는 debian 이미지를 로컬 url 로 태그를 변경한 후에 다시 push 보면 아래와 같이 registry 에 이미지를 저장할 수 있다. 12345$ docker tag debian:latest localhost:5000&#x2F;debian:latest$ docker push localhost:5000&#x2F;debian:latestThe push refers to repository [localhost:5000&#x2F;debian]5d6cbe0dbcf9: Pushed latest: digest: sha256:ec838b15e057f4e5bb42cc194923782c8153e3dbac1a12c32b50d88ef123008a size: 529 이제 호스트에 debian 이미지가 삭제되어도, 컨테이너 저장소 안에 해당 이미지가 존재하므로, docker pull 명령어를 이용하여 해당 이미지를 언제든지 불러올 수 있다. 위와 같은 방식을 이용하여 private registry를 docker container의 형태로 구동하고, custom 이미지를 자유롭게 저장하고 불러올 수 있다. Docker registry configdocker registry를 사용하면, private 한 환경에서 image registry를 구축할 수 있다. 이번에는 단순하게 registry를 사용하는 것 뿐만 아니라 registry 를 배포하고 설정을 변경하여 실제 개발/운영 환경에서 사용하기 위한 추가사항에 대하여 다루어본다. 1. Registry 를 항상 재시작 하도록 설정Docker registry 컨테이너가 구동되는 호스트가 재부팅 되거나, 호스트 내에서 docker process 가 재시작 될 경우 자동으로 registry 컨테이너가 구동되도록 할 경우, container 구동(run)시에 ‘–restart=always’ 옵션을 추가할 수 있다. public registry를 사용하지 않고, 로컬 환경이나 private 환경에서 고정적으로 registry를 사용하는 경우 이 옵션을 부여하여, 호스트의 docker 환경이 재부팅 되더라도 항상 registry가 구동되어 있도록 설정해주자. (사용 예는 아래 3번 예제와 함께 표시한다.) 2. Registry 의 포트를 지정하여 구동registry는 기본적으로 5000번 포트를 사용하여 서비스를 노출한다. 따라서 registry를 사용하기 위해서는 구동시에 port 옵션으로 5000번 포트를 그대로 노출하여 사용하는 것이 일반적이다. 하지만 특별한 경우에 따라서 로컬 환경에서 이미 5000번 포트를 사용하는 경우, container내부의 5000번 포트와 로컬환경의 다른 포트를 연결해줘야 한다. 물론 이렇게 다른 포트를 지정할 수도 있지만, 직관성을 위하여 컨테이너와 호스트에서 동일한 포트를 사용하고자 할 경우 컨테이너 내부의 환경변수로 REGISTRY_HTTP_ADDR 을 지정하여 내부의 registry 포트를 변경하고 동일한 포트로 호스트 포트를 바인딩 할 수도 있다. 아래 3번 예제를 참고하자. 3. Volume directory를 지정registry 는 기본적으로 저장소 역할을 하기 때문에 컨테이너 내부에 계속 해서 데이터(이 경우는 docker image)가 적재 되는 구조이다. 기본적으로 컨테이너 내부의 /var/lib/registry 에 적재되는 데이터는 컨테이너가 삭제될 경우 컨테이너와 함께 삭제되어 유지되지 않는다. 따라서 registry 의 적재되는 데이터는 docker volume 명령어를 이용하여 호스트 환경에 영구적으로(persistent) 유지해 주는 것이 좋다. restart 옵션과 함께 사용할 경우, 호스트 docker 서비스가 중지 되는 경우에도 재기동 후에 registry 안의 데이터를 유지할 수 있다. 컨테이너 내부에 적재되는 데이터는 휘발성이므로, 비단 registry 이미지가 아니더라도, 데이터 성격의 컨테이너의 경우 항상 volume 옵션을 사용해주자. (적재되는 경로는 config 파일에 지정하여 변경 가능하다) 12$ docker run -d --name&#x3D;registry --restart&#x3D;always -e REGISTRY_HTTP_ADDR&#x3D;0.0.0.0:5007 -p 5007:5007 -v &#x2F;registry:&#x2F;var&#x2F;lib&#x2F;registry registry:latest 4. 외부에서 registry 에 접근가능하도록 설정앞에서의 방법을 이용하여 registry를 구동하는 경우 기본적으로 localhost 로만 접근이 가능하다. 즉, 모든 이미지가 local에 있으며 이미지의 full name은 localhost:5000/image:tag 등으로 사용된다. 하지만 아무리 private한 환경에서 사용하기 위한 registry라고 해도 이렇게 로컬 호스트에서만 접근이 가능할 경우 활용성이 매우 떨어진다. 이번에는 private 네트워크 내부의, registry가 떠있는 host로 접근이 가능한, 다른 서버에서 registry를 이용하여 이미지를 저장하고 받아올 수 있도록 registry를 외부로 노출해보자. 먼저 registry가 구동되어 있는 host에 대한 crt 파일과 key 파일을 준비한다. (해당 파일을 생성하는 과정에 대해서는 여기서 다루지 않으니 다른 관련 자료를 참조하자.) 2개의 인증서 파일이 /certs 경로에 있다고 가정할 경우 아래와 같은 구동 명령어를 사용하여 registryf를 구동한다. 12345678docker run -d \\ --name registry \\ -v &#x2F;certs:&#x2F;certs \\ -e REGISTRY_HTTP_ADDR&#x3D;0.0.0.0:443 \\ -e REGISTRY_HTTP_TLS_CERTIFICATE&#x3D;&#x2F;certs&#x2F;server.crt \\ -e REGISTRY_HTTP_TLS_KEY&#x3D;&#x2F;certs&#x2F;server.key \\ -p 443:443 \\ registry:latest 위와 같이 구동할 경우 registry 호스트에 접근가능한 다른 네트워크에서 인증서에 등록된 도메인으로 docker pull/push 등이 가능하다. 5. registry 접근제어안전성이 보증되는 네트워크에서 구동되는 경우가 아니라면 registry 에 대한 접근제어 또한 필요하다. docker registry는 기본적인 패스워드 기반의 인증을 제공하고 있다. 이번에는 registry 내부에서 이미 설치되어 있는 htpasswd 유틸리티를 이용하여 registry 접근 제어를 구현해보자. 먼저 registry 내부의 htpasswd 명령어를 사용하기 위해 아래의 명령을 실행한다. 해당 명령은 아이디와 패스워드를 각각 ‘admin’, ‘password’로 지정하여 특정 위치에 해당 계정 정보와 관련된 파일을 생성해준다. 12$ mkdir $PWD&#x2F;auth$ docker run --entrypoint htpasswd registry -Bbn &quot;admin&quot; &quot;password&quot; &gt; $PWD&#x2F;auth&#x2F;htpasswd 이제 생성된 파일을 이용하여 registry를 구동한다. 1234567$ docker run -d --name registry \\ -v $PWD&#x2F;auth:&#x2F;auth \\ -e &quot;REGISTRY_AUTH&#x3D;htpasswd&quot; \\ -e &quot;REGISTRY_AUTH_HTPASSWD_PATH&quot;&#x3D;&#x2F;auth&#x2F;htpasswd \\ -e &quot;REGISTRY_AUTH_HTPASSWD_REALM&#x3D;Registry Realm&quot; \\ -p 5000:5000 \\ registry 위와 같이 구동할 경우, 지정한 아이디와 패스워드를 이용하여 아래와 같이 로그인이 가능하다. 1$ docker login localhost:5000","categories":[],"tags":[]},{"title":"docker image structure","slug":"docker-image-structure","date":"2020-11-19T00:50:49.000Z","updated":"2020-11-19T09:52:17.174Z","comments":true,"path":"2020/11/19/docker-image-structure/","link":"","permalink":"http://bluefriday.github.io/2020/11/19/docker-image-structure/","excerpt":"","text":"1. 도커 이미지 구조도커 이미지는 HostOS에서 컨테이너를 구동하기 위해 필요한 프로그램, 소스, 유틸리티 등의 모음이다. 이미지를 이용하여 컨테이너를 생성하게 되는데 이는 위의 그림처럼 자바에서의 ‘클래스’, ‘인스턴스’의 개념으로 이해하면 쉽다. 흔히 자바를 공부할 때 붕어빵과 붕어빵틀의 예를 많이 보게된다. 자바 클래스를 이용하여 자바 인스턴스를 생성하는 것과 유사하게 도커 이미지를 이용하여 도커 컨테이너를 생성한다고 이해해도 좋다. 이러한 도커 이미지는 서로 다른 파일시스템으로 구성되어있다. ‘서로 다른 파일시스템’ 이라는 말에 쉽게 이해가 되지 않을 수 있는데 이를 위해 구조적으로 나타내면 아래와 같다. 위의 경우 서로 다른 3개의 층으로 구성되어 있는 스택(층) 구조로 도커 이미지를 표현하였다. 이 때 각각의 층을 Docker에서는 레이어(layer) 라고 부르며 특별히 이미지를 구성하고 있는 레이어를 이미지 레이어라고 부른다. 즉 위의 이미지는 서로 다른 3개의 이미지 레이어로 구성되어 있다고 볼 수 있다. 도커 클라이언트를 통하여 컨테이너를 생성해 달라고 요청(docker run)하면 도커는 먼저 이 이미지를 도커가 관리하는 파일시스템의 영역으로 그대로 복사한다. 그 뒤에 이미지의 최상단에 ‘컨테이너 레이어’ 라고 불리는 하나의 얇은 레이어를 추가하여 컨테이너를 생성한다. 그리고 사용자에게는 유니온 파일 시스템(UnionFS)을 이용하여 마치 이러한 여러개의 파일 시스템(레이어)으로 구성되어 있는 이미지 스택 구조가 하나의 파일 시스템처럼 보이도록 통합된 뷰(view)를 제공해준다. 또한 사용자가 컨테이너 안에서 읽고 쓰는 모든 작업들은 이 컨테이너 레이어에 기록되며, 이미지 레이어에는 기록되지 않는다. 도커 엔진이 파일 시스템을 제어하여 이미지 레이어는 read only 모드로 지정하고, 컨테이너 레이어는 read/write 모드로 지정해주므로 이미지 레이어는 사용자의 작업에 따라 변경 되지 않는다. 따라서 또 다른 사용자가 동일한 이미지를 대상으로 컨테이너를 생성해달라고 요청할 경우, 도커 엔진은 다시 기존의 이미지를 복사하여 그 위에 새로운 컨테이너 레이어만을 레이어 최상단에 올려두고 유니온 파일 시스템을 이용한 통합된 뷰를 제공해준다. 이러한 방식을 통하여 하나의 이미지로 여러 개의 컨테이너를 생성함으로써 디스크 공간을 효율적으로 사용할 수 있다. 하지만 변경되지 않는 이미지 레이어와 달리 컨테이너 레이어는 해당 컨테이너가 삭제 될 때 같이 삭제 된다. 따라서 사용자가 컨테이너 안에서 작업한 모든 읽기/쓰기 작업들은 컨테이너가 제거되는 동시에 같이 지워지게 된다. Docker에서 제공하는 volume 기능을 이용하여 컨테이너 안에서 작업한 내용이나 파일 등을 유지할 수도 있지만 경우에 따라 컨테이너 레이어에서 한 작업을 그대로 유지한 상태의 이미지를 새로 만드는 것이 더 효율적일 때도 있다. 이러한 경우 사용자는 도커 엔진에게 현재의 컨테이너를 이루고 있는 컨테이너 레이어를 이미지 레이어로 변경해 달라고 요청할 수 있다. docker commit 명령어가 이 경우에 사용되며, 이 명령어를 사용할 경우 도커는 해당 컨테이너의 모든 레이어를 이미지 레이어로 변경하여 새로운 이미지를 생성한다. 이 이미지 레이어는 기존에 이미지 레이어에서 컨테이너 레이어가 read only인 이미지 레이어로 변경되어 있는 구성을 이루게 되며, 사용자는 이 이미지를 이용하여 다시 새로운 컨테이너를 생성할 수도 있다. 위의 commit 방식은 도커 이미지를 생성하기 위해서 도커 측에서 제공하는 방법 중 하나이다. Docker image를 생성하기 위한 방법 Dockerfile 을 작성후 build 명령어를 통하여 이미지 빌드 (정적 생성) 구동되어 있는 container 를 대상으로 Docker commit 명령어를 사용하여 동적으로 이미지 생성 Docker save 명령으로 tar파일로 내려받은 이미지를 Docker load 명령어로 로컬 환경에 적재 다만 Commit 명령어를 이용하여 도커 이미지를 생성하는것보다 Dockerfile 을 작성하고 이를 build 하여 새로운 도커 이미지를 생성하는 것을 권장한다. Docker commit 으로 이미지를 생성할 경우 해당 이미지의 이력이 기록되지 않아 이미지의 내용이나 출처를 알기 어려워 유지보수하기 어려워 진다는 단점이 있다. 2. Docker Build와 Image layer서로 다른 파일 시스템으로 구성되어 있는 Docker image 에 대하여 더 쉽게 이해하기 위하여 Dockerfile 과 build 를 이용하여 예를 들면 아래와 같다. 1234567FROM ubuntu:14.04RUN apt-get update &amp;&amp; apt-get install -y nginxRUN chown -R blue:blue &#x2F;var&#x2F;lib&#x2F;nginxRUN mkdir -p &#x2F;home&#x2F;blue&#x2F;my_logCMD [&quot;nginx&quot;] 위 Dockerfile 은 Ubuntu 이미지를 이용하여 nginx를 설치하고 구동하는 간단한 예제이다. (실제 예가 아니며, Dockerfile 의 문법 자체에 대해서는 블로그 내 다른 포스팅을 참조하자.) 이 경우 Docker build 명령어를 이용하여 이미지를 생성할 경우 레이어 구조는 개략적으로 아래와 같다고 볼 수 있다. ubuntu 파일 시스템에서 사용하는 주 디렉토리들을 위와 같이 표현하였다. 최 하단의 base image layer는 ubuntu:14.04의 파일 시스템을 구성하고 있으며, 그 위로 Dockerbuild 파일의 명령어 줄 단위로 레이어가 생기며 해당 레이어에서 실행하는 명령으로 인하여 변경되는 부분에 대해서 해당 레이어가 차이점 (diff or delta 값)을 보관하고 있다. 이러한 방식으로 변경된 내용들을 상위 레이어가 부분적으로 보유하고 있으며, 가장 마지막에 Container layer가 올라가고 그 뒤에 UnionFS 를 사용한다. UnionFS는 하나의 디렉토리에 서로 다른 파일 시스템을 마운트시켜주는 구조인데, 마운트의 특성 상 가장 마지막에 덮어진(mount) 레이어가 보이게 된다. 따라서 여러 개의 파일시스템이 적용되어 있는 디렉토리도 사용자에게는 하나의 파일 시스템처럼 보이는 뷰를 제공해준다. 위와 같은 방식으로 Docker image 가 구성된다고 보면 이해하기 쉽다.","categories":[],"tags":[]},{"title":"dockerfile best practice","slug":"dockerfile-best-practice","date":"2020-11-19T00:38:28.000Z","updated":"2020-11-19T09:41:09.145Z","comments":true,"path":"2020/11/19/dockerfile-best-practice/","link":"","permalink":"http://bluefriday.github.io/2020/11/19/dockerfile-best-practice/","excerpt":"","text":"Dockerfile Best Practice도커 컨테이너를 만들기 위해 사용되는 도커 이미지는 Dockerfile 을 통해서 생성할 수 있다. 물론 commit 명령어를 이용하여 동적으로 컨테이너로부터 이미지를 생성할 수도 있지만, 이미지의 효율적인 관리를 위해서 commit을 사용하는 것보다는 Dockerfile 을 이용하여 이미지를 생성하는 것이 좋다. 여기서는 Dockerfile을 작성할 때 유의해야 하는 사항들에 대하여 정리한다. (해당 내용은 https://docs.docker.com/develop/develop-images/dockerfile_best-practices/ 의 링크를 참조하였습니다.) 설치 구성의 최소화컨테이너는 효율적인 리소스 사용 및 배포의 자동화를 위해, 사용량을 고려하여 손쉽게 scale in/out 될 수 있는 구조다. 따라서 해당 컨테이너가 필요에 따라 생성되거나 삭제될 수 있다는 점을 고려하여, 컨테이너에 필요 이상의 설정을 하지 않고 최소한의 설정/구성으로 구동할 것을 권장한다. 복잡성/의존성을 최소화하기 위하여 해당 이미지에서 구동되는 어플리케이션에 필요한 최소한의 library 만을 설치하는 것이 좋다. 또한 컨테이너가 삭제될 경우 컨테이너 내부의 데이터도 함께 삭제되기 때문에, 사용자에 의해 변경되거나 기록될 수 있는 데이터는 VOLUME 명령어를 이용하여 외부에 적재하는 것이 좋다. ‘.dockerignore’ 파일의 활용빌드 작업을 수행할 때 docker engine은 build script 파일(Dockerfile)이 있는 경로와 모든 하위 경로의 파일/디렉토리를 임시 공간(Docker context)에 저장한 후 build 작업을 수행한다. 이 경우 docker build 에 직접적으로 사용되지 않더라도 해당 경로 하위에 있는 파일/디렉토리가 context에 포함될 수 있다. 이를 방지하기 위하여 .dockerignore 파일을 이용하여 빌드 시에 제외할 파일/디렉토리를 지정할 수 있다. 빌드 되는 컨테이너 이미지의 기능 차이는 없으나, 빌드 성능을 높이기 위하여 build 가 이루어지는 디렉토리에서 .dockerignore 파일을 생성하여 활용하는것을 권장한다. 물론 가장 좋은 방법은 빈 디렉토리를 생성한 후에 Dockerfile과 build에 반드시 필요한 파일/디렉토리만을 해당 디렉토리 내부에 위치하여 container 이미지를 생성하는 방법이다. 1 application per 1 container컨테이너 안에 2개 이상의 어플리케이션을 구동하는 것도 물론 가능하다. 예를 들어 web, was 어플리케이션을 하나의 컨테이너 안에서 구동되도록 할 수도 있다. 하지만 이렇게 1개의 컨테이너 안에 2개 이상의 어플리케이션을 구동하여 사용하는 것은, 컨테이너로 구동되어 있는 어플리케이션 간의 결합성을 높이고 확장성을 떨어트린다. 가령 앞의 경우 web 어플리케이션만 scaling이 되어도 충분한 상황에서 was까지 추가적으로 구동이 될 수 밖에 없다. 자원의 효율적인 확장을 위하여 1개의 컨테이너 안에 웹서버, 데이터베이스 등을 모두 설치하여 사용하는 방식을 지양해야 한다. Dockerfile 스크립트 최소화Docker 이미지의 구성 레이어 수는 Dockerfile 의 예약어 수에 비례한다. 가독성을 높이기 위하여 Dockerfile의 예약어를 여러 라인에 걸쳐 사용할 수 있지만, 레이어의 수가 증가하여 파일크기, 빌드시간 등이 늘어날 수 있으므로 가독성과 이미지 크기를 적절히 고려하여 Dockerfile 스크립트를 구성해야 한다. Caching 기능 활용빌드 시간을 단축하기 위하여 Docker build 엔진의 캐싱 기능을 활용할 수 있다. build engine은 한번 이상 빌드한 Dockerfile의 이미지를 Dockerfile 기준 스크립트 라인 단위로 캐싱 한다. 변경되지 않은 라인의 경우 기존의 캐싱 데이터를 이용하므로, 자주 변경될 수 있는 예약어의 경우 Dockerfile의 하단에 위치하는 것이 좋다. 또한 이와는 반대로 캐싱 기능을 아예 사용하지 않을 경우도 있다. 이 경우에는 FROM 절 바로 밑의 하단에 ENV 변수로 CACHE_TEMP 등의 변수명을 지정해주고 빌드를 할 때, 이 변수의 값을 임의의 난수로 지정해주면 된다. 해당 변수는 컨테이너 이미지 안에서 사용되지 않고, 의미없는 변수로 남게 되지만 Dockerfile의 해당 라인이 변경되었으므로 build engine은 FROM 절 바로 밑 라인부터 캐시를 사용하지 않고 다시 빌드를 수행할 수 있다. Command instructionFROMBase 이미지의 경우 docker hub에서 제공하는 official 이미지를 사용하는 것을 권장한다. official 이미지는 docker principle 에 따라 최소한의 설치 요소로 구성되어 있다. 이 외에도 자주 사용하는 라이브러리가 있을 경우, 자신에게 커스터마이징 된 이미지를 미리 생성해놓고 해당 이미지를 base 이미지로 사용하는 것도 좋은 방법이다. ENVENV 예약어는 구동 되어질 컨테이너 내부의 환경변수를 정의한다. WORKDIR, USER 등의 명령어를 조합하여 사용하지 않는 경우, 환경변수 PATH에 어플리케이션의 경로를 추가하여 구동 시 임의의 위치에서 명령어가 실행 될 수 있도록 지정할 수 있다. 또한 환경변수로 설치된 어플리케이션의 major, minor version을 명시하거나, 이미지 생성일시 등을 기록해두면 직관성을 높이고 유지보수에도 도움이 된다. 또한 위에 서술한 내용과 같이 Dockerfile 의 cache를 없애고 싶을 때도 활용할 수 있다. ADD, COPY 명령어ADD, COPY는 모두 이미지 build가 이뤄지는 호스트 환경의 파일을 컨테이너 내부로 복사한다는 점에서는 동일한 기능을 수행하지만, 세부적인 기능에서 차이가 있으므로 이를 구분하고 적절하게 사용하는 것이 좋다. COPY 예약어는 host 환경의 파일, 디렉토리를 대상 컨테이너 이미지 안으로 복사하는 기능만을 수행한다. 이에 비해 ADD 예약어는 2가지 기능을 추가로 제공한다. 첫번째로 제공하는 기능은 ‘Auto-extraction’ 기능이며 이는 복사하는 대상 파일이 압축 파일(tar, tar.gz)일 경우, 해당 파일의 압축을 해제하여 복사해준다. 또한 ‘Remote-URL’ 기능을 제공하여 wget등을 통하여 원격지의 파일을 복사할 파일로 지정할 수 있다. 그러나 직관성이 떨어지므로, 2가지 기능을 반드시 사용해야하는 경우가 아니라면 상대적으로 직관성이 더 높은 COPY 명령어를 권장한다. RUN 명령어RUN 명령어는 컨테이너 안에서 쉘 명령어를 사용할 수 있는 예약어다. 이미지를 커스터마이징하기 위해서 매우 높은 빈도로 사용되며, Dockerfile 을 작성하면서 RUN 명령어를 사용하는 대부분의 경우는 apt-get(debian,ubuntu), yum(centos) 등을 라이브러리를 설치하기 위해 사용된다. 이 경우, 최소 구성을 위하여 자동 update 기능을 지양하는 것이 좋다. apt-get 명령어를 사용할 경우 불필요한 apt-get upgrade 등의 명령어를 사용하지 않을 것을 권장한다. upgrade 명령어를 같이 사용할 경우, 최소 구성을 위한 설치 이외의, 권장되지만(nice to have) 반드시 필요하지는 않는 라이브러리 또한 함께 설치되어 이미지 레이어 크기가 증가한다. 또한 여러 개의 라이브러리를 설치할 경우, 라이브러리 간 판별성을 높이기를 위하여 알파벳순으로 정렬한 후 개행문자()를 이용하여 여러라인으로 표시하는 것이 좋다. cachinig 방식 유의(cache busting)Docker engine은 ADD, COPY 이외의 명령어에 대하여 string 값을 비교하여 캐싱 작업을 수행한다. 예를 들어, 1214: RUN apt-get update 15: RUN apt-get install -y curl 위의 빌드 스크립트를 포함한 docker image를 생성하여 사용한 후에, 사용 뒤의 용도 변경으로 인하여 1214: RUN apt-get update 15: RUN apt-get install -y curl nginx 위와 같이 변경하였을 경우, docker engine은 14번째 라인까지 캐싱 값을 사용하여 15번째 라인부터 명령어를 수행한다. 이 경우 최신 update를 사용하지 않게 되어, nginx 가 latest버전으로 설치 되지 않을 수 있다. 설치하는 library, middle ware 의 최신화를 위화여 update 구문은 항상 114: RUN apt-get update &amp;&amp; apt-get install something... 위와 같이 파이프라인을 통하여 함께 수행하는것을 권장한다. apt, yum 캐시 제거apt-get update, apt-get install 명령어를 수행한 후에 파이프라인을 통하여 apt cache를 제거하면 레이어의 크기를 줄일 수 있다.위의 instruction을 정리하여 아래와 같은 방식으로 apt-get 명령어를 수행하는 것을 권장한다. 12345RUN apt-get update \\ &amp;&amp; apt-get install -y --no-install-recommends libjemalloc1 \\ curl \\ nginx \\ &amp;&amp; rm -rf &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;* Using pipes1RUN wget -O - https:&#x2F;&#x2F;some.site | wc -l &#x2F; number 위의 구문 같은 경우 wget 의 성공/실패 여부와 상관없이 그 결과 출력의 wc -l 구문 결과가 /number에 성공적으로 저장되면서 docker build engine은 이 경우 언제나 성공으로 인식한다. build 초기에 잡히는 구문 오류가 아닌, 이러한 논리적 오류을 없애기 위해선 1RUN set -o pipefail &amp;&amp; wget -O - https:&#x2F;&#x2F;some.site | wc -l &#x2F; number 이런식으로 set -o option을 같이 적용해줘야 한다.","categories":[],"tags":[]},{"title":"docker image garbage collection","slug":"docker-image-garbage-collection","date":"2020-11-19T00:32:48.000Z","updated":"2020-11-19T09:34:53.438Z","comments":true,"path":"2020/11/19/docker-image-garbage-collection/","link":"","permalink":"http://bluefriday.github.io/2020/11/19/docker-image-garbage-collection/","excerpt":"","text":"1. Docker image의 물리적 삭제Docker image는 registry 에 저장될 때 image의 레이어 단위로 저장이 되며, 이렇게 저장된 레이어는 registry 의 내부에서 manifest 파일에 의해서 참조 된다. 또한 사용되지 않는 registry 의 물리적 이미지 삭제는 Registry Garbage Collection (이하 Registry GC) 에 의해서 수행되며, Registry GC가 수행될 때 사용되지 않는(어떤 manifest파일에서도 참조하지 않는) blob 파일들이 삭제 되면서 용량이 확보된다. 단계적으로 보면 아래와 같다. mark phase : registry 내부의 manifest 를 검색하여 manifest 가 참조하고 있는 image layer 에 대하여 마킹 sweep phase : 마킹이 되어 있지 않는 image layer에 대하여 레이어 삭제 수행 하지만, 이러한 Registry GC는 자동으로 수행되지 않으며, 명시적으로 수행하여 파일을 삭제하기 위해서 아래의 작업이 필요하다. 먼저 아래와 같이 Registry Config 설정을 수정하여 삭제가 가능하도록 delete 플래그를 변경(disable -&gt; enable) 하여야 한다. 기존에 구동되어 있는 registry가 해당 플래그가 선언되어 있지 않다면, registry config 를 수정한 후에 컨테이너를 재기동하자. 이를 위해서 registry config 또한 docker volume 으로 외부 파일로 연결하는 것이 좋다. 1)그 후에 Docker registry API 를 이용하여 삭제할 image의 content-digest 를 조회한다. 그리고 2)조회한 digest 값을 이용하여 image manifest 를 삭제한다. image manifest를 삭제할 경우 논리적 삭제만 이뤄지며 실제로 물리적으로 디스크에서 이미지가 지워지지는 않는다. 물리적 삭제를 위해서 컨테이너 내부에서 ‘garbage-collect 명령어를 수행하여 Registry GC를 수동으로 수행한다. 위의 1), 2)와 명시적 gc 수행 명령어는 이 글의 최하단의 ‘관련 명령어’ 를 참조하자. 1234567891011version: 0.1... storage: delete: enabled: false (-&gt; true 로 변경)... 2. Image에 삭제에 따른 storage 용량 확보위에서 소개한 것과 같이, docker image layer는 registry 내부의 모든 manifests 파일이 참조하지 않는 레이어에 대하여만 GC 시, 삭제를 수행한다. 이와 같이 여러개의 manifests 파일이 동일한 이미지 레이어를 참조하는 구조로 인하여, 특정 이미지를 삭제 하는 것이 disk 확보와 직결되지 않을 수 있다. 아래의 그림을 예시로 보자. image A와 image B는 서로 동일한 레이어를 포함하고 있다. 이와 같은 구조는 실제 도커 이미지를 빌드할 때, 같은 베이스 이미지를 사용하여 빌드를 계속 수행할 경우 나타날 수 있다. 이런 경우에 최종 빌드 이미지만을 남겨 놓기 위하여 image A를 삭제하는 경우 image B가 참조하고 있는 layer 들로 인하여 실제로 layer a,b,c 는 삭제 되지 않는다. 이와 다른 경우로 오른쪽의 그림을 보면 하나의 베이스 이미지로 여러가지 버전이 존재 한다. image C, D, E, F 중 일부를 삭제 하는 경우 해당 image에서만 사용하고 있는 레이어도 같이 삭제하여 디스크를 확보할 수 있다. 위와 같은 이미지 레이어의 참조 구조를 고려하여 도커 이미지를 빌드하거나 혹은 삭제하는 것이 좋다. #@# 3. Caching 기능에 따른 re-push 문제위와 같은 방식을 이용하면 특정 이미지를 물리적으로 제거할 수 있다. 하지만 이렇게 Registry GC를 수행한 후에 동일한 [이미지]:[태그]로 다시 push 할 경우에는 push가 수행 되는 것처럼 보이지만 내부적으로는 실제 push가 일어나지 않는다. 따라서 push 후에 동일한 이미지명으로 pull 할 경우에도 image가 존재하지 않는다는 오류가 발생한다. 이는 docker registry config에 caching 기능이 지정되어 있어 발생한다. Registry는 image layer에 접근을 빠르게 하기 위하여 caching 기능을 기본적으로 사용하며, inmemory, redis 등의 옵션으로 사용되어진다. 이 caching 기능을 없애기 위하여 registry config 파일에서 caching 과 관련된 항목을 제거한다. 반대로 caching을 기능 없애지 않는 경우에는, cache 를 수동으로 없애기 위하여 registry 컨테이너를 재시작하는 방법 또한 가능하다. 즉, 물리적 이미지 삭제 이후에 re-push가 되지 않는 문제를 해결하기 위해서는 1) in-memory cache를 지우기 위하여 registry 컨테이너를 재시작하거나, 2)구동하는 시점부터 cache 기능을 사용하지 않도록 설정하는 방법을 사용할 수 있다. (추가적으로 캐시 저장소를 redis를 사용하는 방법이 있으나 이는 별도로 기술한다.) 하지만 cache 를 없애기 위한 위 2가지 방식과 무관하게, disk size를 줄이기 위하여 수행해야 하는 GC 수행은 반드시 registry의 image로 구동되어 있는 container가 없으며, pull/push 가 일어나지 않는 중에 수행 되어야 한다. 그렇지 않을 경우, 기존 image가 깨지거나 pull/push 중이던 image가 손상될 수 있다. 결론위의 방법 중 어떤 방법을 사용하더라도, 실제로 GC가 일어나는 중에는 registry의 기능이 정지되어 있어야 한다. 어차피 GC를 위하여 registry의 기능을 사용하지 않는다면, 캐싱기능을 그대로 사용하고 registry를 재시작하는 방법을 권장한다. 결과적으로 registry 삭제를 통한 disk 확보는 docker image 의 multi-layer 구조를 고려하여 진행하는 것이 좋으며, 삭제하지 않을 경우에는 처음부터 충분한 공간의 storage를 확보하는 것이 좋다. 관련 명령어registry 와 관련된 API를 활용한 명령어는 아래와 같으며, 아래의 순서대로 차례대로 명령을 수행하여 해당 이미지를 논리적/물리적으로 삭제할 수 있다. 123456789101112131401. registry 내부의 repository 정보 조회$ curl -X GET &lt;REGISTRY URL:포트&gt;&#x2F;v2&#x2F;_catalog02. repository 에 대하여 tag 정보 조회$ curl -X GET &lt;REGISTRY URL:포트&gt;&#x2F;v2&#x2F;&lt;REPOSITORY 이름&gt;&#x2F;tags&#x2F;list03. content digest 조회$ curl -v --silent -H &quot;Accept: application&#x2F;vnd.docker.distribution.manifest.v2+json&quot; -X GET http:&#x2F;&#x2F;&lt;REGISTRY URL:포트&gt;&#x2F;v2&#x2F;&lt;REPOSITORY 이름&gt;&#x2F;manifests&#x2F;&lt;TAG 이름&gt; 2&gt;&amp;1 | grep Docker-Content-Digest | awk &#39;&#123;print ($3)&#125;&#39;04. manifest 삭제$ curl -v --silent -H &quot;Accept: application&#x2F;vnd.docker.distribution.manifest.v2+json&quot; -X DELETE http:&#x2F;&#x2F;&lt;REGISTRY URL:포트&gt;&#x2F;v2&#x2F;&lt;REPOSITORY 이름&gt;&#x2F;manifests&#x2F;&lt;DIGEST 정보&gt;05. GC(Garbage Collection)$ docker exec -it registry_dev registry garbage-collect &#x2F;etc&#x2F;docker&#x2F;registry&#x2F;config.yml","categories":[],"tags":[]},{"title":"docker overview","slug":"docker-overview","date":"2020-11-18T23:50:09.000Z","updated":"2020-11-19T09:28:19.572Z","comments":true,"path":"2020/11/18/docker-overview/","link":"","permalink":"http://bluefriday.github.io/2020/11/18/docker-overview/","excerpt":"","text":"1. Container 기술과 Docker기존의 시스템 관리자들은 서비스를 제공하는 서버를 관리하기 위하여 VM(Virtual Machine, 가상머신)을 사용하여 자원을 관리해왔다. VM을 사용하는 서버 관리 방식은 물리적 서버를 직접 운영하는 것보다 효율적이었지만, Host OS 위에 Guest OS를 구동하는 구조로 인하여 가상화(hypervisor 레이어) 자체에 대한 비용이 존재하였다. 또한 서비스의 규모가 커지거나, 사용시간 등에 따라 사용량이 수시로 변경되면서 자원을 효율적으로 관리하기 위한 스케일에 대한 필요성도 증가하였다. 이러한 환경에서 등장한 컨테이너 기술은 Guest OS를 생성하여 시스템 자체를 가상화 하는 것이 아닌, 어플리케이션의 구동 환경을 가상화 하는 기술이다. 기존에 사용하던 VM이 Host OS 위에 Hypervisor Tool 을 이용하여 Guest OS 를 구동하는 것에 비해, 컨테이너 서비스는 Host OS 위에 직접 어플리케이션의 실행환경을 가상화 시켜준다. GuestOS 가 없기 때문에 VM에 비하여 가볍고 구동시간 또한 더 빠르다. 애초에 OS가 아니라 프로세스가 구동되는 개념이어서, 부팅 속도가 VM에 비해 더 빠를 수 밖에 없다. 이러한 이유로 컨테이너는 Lightweight VM 이라고도 불린다. 빠른 부팅 속도로 인하여 스케일링, fail-over 등에도 효율적이다.또한 Hypervisor 가 없이 바로 HostOS 의 자원을 사용할 수 있기 때문에 VM에 비해 더 효율적인 자원 사용이 가능하다. 정리하면 아래와 같은 장점을 가지고 있다고 볼 수 있다. 가상화 기술보다 가볍고 성능이 좋으면서도 동일한 Bard Metal/Virtual Machine 에서 더 많은 어플리케이션을 구동할 수 있다. 빠른 빌드와 배포, 이식성을 제공하므로 이를 통해서 개발을 더 쉽고 빠르게 할 수 있고 확장성을 높힐 수 있다. 개발에서 운영으로의 이관이 용이하며, DevOps 패러다임에 유리하다. Host Kernal 레벨을 공유하며 OS를 따로 부팅하지 않으므로 VM에 비하여 부팅속도가 매우 빠르다. 그러나 실제로는 GuestOS가 없다는 표현 보다는 HostOS를 Linux 로 고정 시킨 것에 가깝기 때문에, Linux OS 가 아닌 OS. 예를 들면 windows OS 에서만 작동하는 어플리케이션은 컨테이너로 구동할 수 없다는 단점도 있다. 이러한 장점과 단점을 가진 컨테이너 기술은 사실 갑자기 등장한 개념은 아니다. 서버 관리자들은 이미 chroot, namespace 등의 컨테이너를 구성하는 프로세스 격리 기술을 사용해 왔으며 최근에 사용성이 증가되면서 ‘컨테이너’ 라는 개념으로 새롭게 조명되고 있다. 즉, ‘빅데이터’나 ‘클라우드’와 같이 마케팅 성격이 다소 포함된 개념으로 볼 수 있다. 이 블로그에서 소개하고 있는 Docker 서비스는 Linux 환경에서 컨테이너 기술을 사용하기 쉽게 만들어놓은 시스템 프로그램(서비스)이다. 내부적으로 리눅스에 내장되어 있는 OS 레벨의 가상화 기술인 리눅스 컨테이너 기술(LXC)을 사용한다. Docker와 같은 컨테이너 서비스는 Linux 에서만 존재하는 기술은 아니며 이외의 Unix / BSD 계열에서도 컨테이너라는 명칭을 사용하지 않을 뿐 아래와 같은 가상화 기술을 제공하고 있다. Linux : Docker FreeBSD : Jails AIX : 워크로드 파티션(AIX Workload Partitions) Solaris : Zone 2. Docker installDocker는 리눅스에서 제공하는 컨테이너 서비스이므로 당연히 LInux 계열의 OS 인 Debian, Centos, Ubuntu 등의 OS에서 설치하는 것이 가장 쉽고 편하다. 추가적으로 Linux 이외의 Mac OS, Windows OS 등에서도 Docker를 설치할 수 있도록 가이드와 패키지를 제공하고 있다. Windows 에서 Docker를 설치 하기 위해서는 Windows 환경 위에 Linux OS 를 Guest로 구성해야 한다. 물론 Guest OS를 사용하지 않기 위한 것이 Docker 사용의 주요 목적이므로, docker를 설치하기 위해 Guest OS를 구성하는 것은 매우 비효율적이고 부자연스러운 방식이나 실 운영 서비스를 위해서가 아닌 개발 및 검증 목적으로 설치할 경우는 이와 같은 방식으로도 설치가 가능하다. 대부분의 경우 VMWare 나 Oracle Virtualbox 등의 hypervisor tool 을 설치하고 그 위에 Linus OS(ubuntu, centos)를 GuestOS로 구동하고 다시 그 안에서 도커를 설치한다. (전술했듯이 복잡하고 성능상으로는 다소 불리한 방법이니 테스트 등의 목적으로만 사용하는 것이 좋다.) 이와는 별개로 Docker 측에서는 위와 같은 작업을 이미 packaging 화하여 ‘Docker toolbox’라는 설치 패키지를 제공한다. 실제로 Docker Toolbox 안에는 Oracle virtualBox 가 포함되어 있다. 편한 방법을 사용하여 도커를 설치하도록 하자. 또한 Windows 10의 경우 docker toolbox 이외에 Docker for windows 라는 별도의 설치패키지를 지원한다. docker toolbox와 유사하나 windows에서 제공하는 windows container 를 위한 패키지가 추가 되었다고 보면 된다. (Docker container 가 host OS 가 linux 를 사용하는 것과 반대로 Windows container 는 host OS를 Windows로 사용한다고 보면 이해가 쉽다) 각각의 OS에서 Docker를 설치하는 링크나 패키지는 아래와 같으므로 필요에 따라 해당 내용을 검색하여 설치를 권장한다. Ubuntu : https://docs.docker.com/install/linux/docker-ce/ubuntu/ Centos : https://docs.docker.com/install/linux/docker-ce/centos/ Mac OS : Docker for Mac, Docker Toolbox Windows 7 : Docker Toolbox Windows 10 : Docker for windows 3. Docker version컨테이너 개념에 대하여 소개하면서 서술하였듯이, ‘컨테이너’라는 개념은 이미 존재하고 있는 시스템 개념이며 Docker는 이를 사용하기 쉽게 패키징한 서비스이다. Docker 진영은 2013년 1월에 0.1.0 버전으로 처음 release 하여 계속해서 버그를 수정하고 새로운 기능을 계속 추가해 오다가 1.6버전에서부터 enterprise 성격의 cs-docker(cs : Commercial Supported)를 출시한다. 또한 2017년에는 그 동안의 표기인 docker, cs-docker 를 docker-ce, docker-ee로 각각 변경하고 기존의 major / minor 버전 표기법을 year.month 의 연월 표기법으로 변경하여 사용한다. Docker-CE : Community 버전. 분기별로 새로운 버전이 출시되며, 실험적인 기능을 포함하고 있는 edge 버전이 매달 release 된다.Docker-EE : Enterprise 버전. 분기별로 새로운 버전이 출시된다.","categories":[],"tags":[]}],"categories":[],"tags":[]}